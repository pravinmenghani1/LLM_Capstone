# ðŸŽ“ Workshop Facilitator Guide
## EcoTech Crisis Management Workshop

---

## ðŸŽ¯ **Pre-Workshop Setup (30 minutes before)**

### **Room Setup:**
- **Teams of 3-4 people** (max 6 teams total)
- **Each team needs:** Laptops, internet access, shared screen/projector
- **Materials:** Crisis brief packets, review datasets, scoring sheets
- **Tools Access:** ChatGPT, Zapier accounts, demo tools ready

### **Facilitator Preparation:**
- [ ] Test all AI tools and internet connectivity
- [ ] Print crisis brief packets (1 per team)
- [ ] Prepare scoring rubrics
- [ ] Set up timer/countdown for each phase
- [ ] Have sample solutions ready for comparison

---

## ðŸš€ **Workshop Execution Guide**

### **Opening (5 minutes)**
**Script:**
> "You're about to experience what it's like to use AI tools under real business pressure. This isn't a demo - you'll actually solve a crisis using the same tools companies use every day. Your decisions and speed will determine if a $2M product launch succeeds or fails."

**Key Points:**
- This is hands-on, not watching
- Time pressure is intentional (mirrors real business)
- Teams will compete but also learn from each other
- Focus on practical application, not perfect solutions

---

### **Phase 1: Crisis Assessment (10 minutes)**

#### **What Facilitator Does:**
1. **Distribute crisis brief packets** to each team
2. **Start 10-minute timer**
3. **Circulate and listen** to team discussions
4. **Answer clarifying questions** about the scenario
5. **Give 2-minute warning**

#### **What Teams Should Be Doing:**
- Reading and understanding the crisis
- Assigning roles (Content Manager, Data Analyst, etc.)
- Planning their approach and tool usage
- Creating a quick action plan

#### **Facilitator Coaching Tips:**
- "Don't overthink the planning - you'll learn by doing"
- "Make sure everyone has a clear role"
- "Focus on what needs to be delivered, not how perfect it needs to be"

#### **Red Flags to Watch For:**
- Teams spending too much time planning
- Unclear role assignments
- Not understanding the time pressure

---

### **Phase 2: Content Creation Sprint (25 minutes)**

#### **What Facilitator Does:**
1. **Start 25-minute timer**
2. **Monitor team progress** - are they actually using AI tools?
3. **Provide quick guidance** on tool usage if teams are stuck
4. **Give time warnings** at 15 min, 10 min, 5 min remaining
5. **Collect deliverables** at the end

#### **What Teams Should Deliver:**
- **Content Manager:** Product descriptions in 5 languages + social posts
- **Others:** LinkedIn profiles for 3 sales managers

#### **Common Issues & Solutions:**
- **"ChatGPT isn't working"** â†’ Have backup accounts ready
- **"Translations look wrong"** â†’ Remind them to ask for cultural adaptation
- **"We're running out of time"** â†’ Focus on completion over perfection

#### **Quality Check Questions:**
- Are translations culturally appropriate or just word-for-word?
- Do LinkedIn profiles sound professional and compelling?
- Is the content consistent with the brand voice?

---

### **Phase 3: Customer Intelligence (20 minutes)**

#### **What Facilitator Does:**
1. **Provide customer review dataset** to Data Analysts
2. **Start 20-minute timer**
3. **Check that teams are analyzing, not just reading** reviews
4. **Help teams focus on actionable insights**
5. **Collect sentiment analysis results**

#### **What Teams Should Deliver:**
- Sentiment analysis summary with scores
- Top 3 urgent issues identified
- Response templates for different sentiment types
- Positive testimonials selected for marketing

#### **Coaching During This Phase:**
- "Don't just categorize - what actions should the company take?"
- "Which reviews would you escalate immediately?"
- "What patterns do you see across different markets?"

#### **Success Indicators:**
- Teams identify the critical negative review (device failure)
- They recognize positive patterns (solar efficiency, IoT features)
- Response templates are professional and appropriate

---

### **Phase 4: Automation Setup (20 minutes)**

#### **What Facilitator Does:**
1. **Start 20-minute timer**
2. **Help teams think through workflow logic**
3. **Ensure they're designing complete workflows, not just lists**
4. **Check that escalation rules make business sense**

#### **What Teams Should Deliver:**
- Customer support automation workflow
- Social media monitoring workflow
- Clear trigger conditions and action sequences
- Escalation rules that make business sense

#### **Key Questions to Ask Teams:**
- "What happens if the AI gets the sentiment wrong?"
- "How do you handle edge cases?"
- "What's the backup plan if automation fails?"

#### **Red Flags:**
- Workflows that are too simple (just "route to support")
- No consideration of edge cases or failures
- Escalation rules that don't match business priorities

---

### **Phase 5: Quality Assurance (10 minutes)**

#### **What Facilitator Does:**
1. **Start 10-minute timer**
2. **Provide quality checklist** to teams
3. **Help teams focus on critical validation points**
4. **Prepare for scoring while teams work**

#### **What Teams Should Do:**
- Check consistency across all their deliverables
- Validate product specifications and pricing
- Ensure brand message alignment
- Identify any critical errors or gaps

#### **Facilitator Focus:**
- Are teams actually checking their work or just claiming it's good?
- Do they catch obvious inconsistencies?
- Are they prioritizing the most important quality issues?

---

### **Phase 6: Crisis Resolution Presentations (5 minutes per team)**

#### **Presentation Format:**
Each team gets **exactly 2 minutes** to present:
1. **What we accomplished** (30 seconds)
2. **Quality metrics achieved** (30 seconds)
3. **Time/cost savings vs traditional approach** (30 seconds)
4. **Our recommendation: Launch or delay?** (30 seconds)

#### **Facilitator Role:**
- **Strict timekeeper** - cut off at 2 minutes
- **Ask one challenging question** per team
- **Take notes for scoring**
- **Keep energy high and competitive**

#### **Sample Challenging Questions:**
- "What's your biggest risk if you launch today?"
- "How do you know your translations are actually accurate?"
- "What happens if your automation workflows fail on launch day?"

---

## ðŸ“Š **Scoring and Debrief (15 minutes)**

### **Live Scoring Process:**
1. **Score each team** using the rubric while they present
2. **Announce results dramatically** (build suspense!)
3. **Celebrate the winners** but acknowledge all efforts
4. **Show sample solutions** for comparison

### **Scoring Rubric (100 points total):**

#### **Content Quality (30 points)**
- **Translation accuracy (10 pts):** Are translations culturally appropriate?
- **Cultural adaptation (10 pts):** Do they understand local markets?
- **Brand consistency (10 pts):** Is messaging aligned across all content?

#### **Customer Intelligence (25 points)**
- **Sentiment analysis (10 pts):** Did they identify key patterns?
- **Action plan quality (10 pts):** Are recommendations actionable?
- **Response templates (5 pts):** Are they professional and appropriate?

#### **Automation Setup (25 points)**
- **Workflow completeness (15 pts):** Are workflows actually implementable?
- **Business logic (10 pts):** Do escalation rules make sense?

#### **Data Quality (20 points)**
- **Consistency checks (10 pts):** Did they catch errors and inconsistencies?
- **Error identification (10 pts):** Did they prioritize critical issues?

### **Results Announcement:**
```
"Team Alpha: 87 points - LAUNCH HERO! ðŸ¥‡
The launch proceeds as planned. You saved the company $2M!"

"Team Beta: 76 points - LAUNCH SAVER! ðŸ¥ˆ  
Launch delayed 1 day for fixes, but crisis averted!"
```

---

## ðŸŽ“ **Debrief Discussion (10 minutes)**

### **Key Questions for Group Discussion:**
1. **"What surprised you most about using AI tools under pressure?"**
2. **"Where did AI help the most? Where did it struggle?"**
3. **"How would this compare to doing everything manually?"**
4. **"What would you do differently in a real crisis?"**

### **Learning Points to Emphasize:**
- **AI amplifies human capability** but doesn't replace judgment
- **Speed vs quality tradeoffs** are real business decisions
- **Integration between tools** is where the real value comes from
- **Human oversight** is critical for quality and context

### **Real-World Applications:**
- "Which of these scenarios could happen in your organization?"
- "What AI tools would be most valuable for your specific industry?"
- "How would you get started implementing this approach?"

---

## ðŸš¨ **Troubleshooting Guide**

### **Common Workshop Issues:**

#### **Teams Moving Too Slowly:**
- **Solution:** Emphasize time pressure, give frequent time warnings
- **Script:** "In a real crisis, perfect is the enemy of done"

#### **AI Tools Not Working:**
- **Solution:** Have backup accounts and alternative tools ready
- **Script:** "This is why companies need backup plans for AI tools"

#### **Teams Getting Stuck on Details:**
- **Solution:** Redirect to business impact
- **Script:** "Will this detail affect the $2M launch decision?"

#### **Uneven Team Performance:**
- **Solution:** Provide targeted coaching to struggling teams
- **Script:** "What's the minimum viable solution to save the launch?"

#### **Teams Finishing Too Early:**
- **Solution:** Challenge them to improve quality
- **Script:** "Great! Now make it 20% better in the remaining time"

---

## ðŸŽ¯ **Success Metrics for Facilitator**

### **Workshop Success Indicators:**
- [ ] All teams actively engaged throughout
- [ ] Teams actually use AI tools (not just discuss them)
- [ ] Competitive energy maintained
- [ ] Real learning moments visible
- [ ] Participants ask "How do I implement this at work?"

### **Post-Workshop Follow-up:**
- Share sample solutions and best practices
- Provide tool access guides and tutorials
- Offer follow-up consultation for implementation
- Collect feedback for workshop improvement

**Remember: This workshop succeeds when participants experience the power of AI integration firsthand, not just hear about it!** ðŸš€
